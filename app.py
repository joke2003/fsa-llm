import streamlit as st
import pandas as pd
import io
import json 
import os 
from datetime import datetime
from docx import Document 
import PyPDF2 
import concurrent.futures 
import re # Ensure re is imported

# --- Import from new modules ---
# These imports should NOT cause any Streamlit commands to run at import time.
from config import (
    APP_TITLE, APP_ICON, ANALYSIS_FRAMEWORK_SECTIONS, 
    ALL_DEFINED_MODULES_LIST, TOTAL_MODULES_COUNT,
    BASE_RESULT_DIR, PROMPTS_VERSION # Added PROMPTS_VERSION
)
# logger.py, llm_setup.py etc. are imported below after page_config

# --- !!! THIS MUST BE THE FIRST STREAMLIT COMMAND !!! ---
st.set_page_config(layout="wide", page_title=APP_TITLE, page_icon=APP_ICON)

# --- Now, import custom modules that might use Streamlit commands internally ---
# It's generally safer if these modules also avoid top-level st calls,
# but if they do (e.g. @st.cache_resource on a function), their import
# itself isn't the issue, it's when those functions are CALLED.

from logger import log_event
from llm_setup import get_llm_instance # Import the function, don't call it yet
from utils import (
    sanitize_filename, create_run_result_directory, get_latest_period_info,
    format_core_statements_for_llm, get_prior_analyses_summary 
)
from document_processing import preprocess_document_text 
from planning_services import (
    get_ai_planned_analysis_route, 
    plan_all_module_information_needs
)
from core_analysis_engine import run_llm_module_analysis 
from reporting import generate_and_save_html_report
from integration_services import consolidate_risks_and_opportunities, update_overall_conclusion_and_log_contradictions

# Try importing prompts.py after set_page_config, and handle error gracefully without st.error here
try:
    from prompts import MODULE_PROMPTS
except ImportError:
    # Log the error, but don't use st.error before the main app layout is built
    # This will be caught and displayed in the sidebar later if llm (and thus prompts) are needed.
    if 'run_log' not in st.session_state: st.session_state.run_log = [] # Ensure run_log exists
    log_event("CRITICAL_ERROR", "prompts.py æ–‡ä»¶æ— æ³•å¯¼å…¥ã€‚åº”ç”¨åŠŸèƒ½å°†ä¸¥é‡å—é™ã€‚", "AppSetup")
    MODULE_PROMPTS = {"DEFAULT_PROMPT": {"main_prompt_template": "é”™è¯¯ï¼šæç¤ºæ¨¡å—æ— æ³•åŠ è½½ã€‚"}}


# --- Core Working Paper (CWP) & Session State Initialization ---
def initialize_cwp():
    return {
        "base_data": { 
            "company_info": {
                "analysis_perspective": "è‚¡æƒæŠ•èµ„", 
                "macro_analysis_conclusion_text": "ç”¨æˆ·æœªæä¾›å®è§‚ç»æµåˆ†æç»“è®ºï¼Œä¸”æœªä»æµ‹è¯•ç›®å½•åŠ è½½é»˜è®¤æ–‡ä»¶ã€‚", 
                "industry_analysis_conclusion_text": "è¡Œä¸šåˆ†æç»“è®ºï¼ˆåŸºäºæ³¢ç‰¹äº”åŠ›æ¨¡å‹ï¼‰å°šæœªç”Ÿæˆã€‚",
                "ai_planner_enabled": False 
            }, 
            "financial_reports": [] 
        },
        "analytical_module_outputs": {}, 
        "integrated_insights": { 
            "overall_summary": "", 
            "key_risks": [], 
            "key_opportunities": [],
            "current_overall_financial_conclusion": "åˆ†æå°šæœªå¼€å§‹ï¼Œæš‚æ— æ€»ä½“ç»“è®ºã€‚", 
            "contradiction_logbook": [] 
        },
        "metadata_version_control": {
            "app_version": "0.10.2", # Corrected set_page_config execution order
            "analysis_timestamp": None, "llm_model_used": "DeepSeek (Conceptual)",
            "prompts_version": PROMPTS_VERSION, 
            "ai_planned_modules": None,
            "ai_planned_sections_for_display": None,
            "information_needs_by_module": {} 
        }
    }

# Initialize session state variables if they don't exist
if 'cwp' not in st.session_state: 
    st.session_state.cwp = initialize_cwp()
if 'run_log' not in st.session_state: # Must be initialized before get_llm_instance() if logger is used there
    st.session_state.run_log = [] 
if 'analysis_started' not in st.session_state: 
    st.session_state.analysis_started = False
if 'analysis_progress' not in st.session_state: 
    st.session_state.analysis_progress = 0
if 'current_module_processing' not in st.session_state: 
    st.session_state.current_module_processing = "ç­‰å¾…å¼€å§‹..."
if 'num_periods_to_upload' not in st.session_state: 
    st.session_state.num_periods_to_upload = 1
if 'test_data_loaded_successfully' not in st.session_state: 
    st.session_state.test_data_loaded_successfully = False
if 'current_run_result_dir' not in st.session_state: 
    st.session_state.current_run_result_dir = None
if 'analysis_perspective_default' not in st.session_state: 
    st.session_state.analysis_perspective_default = "è‚¡æƒæŠ•èµ„"
if 'ai_planner_toggle_default' not in st.session_state: 
    st.session_state.ai_planner_toggle_default = False

# --- Initialize LLM instance AFTER set_page_config and session_state init ---
llm = get_llm_instance() # This will trigger @st.cache_resource and st.secrets.get()


# --- Main UI and Workflow ---
st.title(f"{APP_ICON} {APP_TITLE}")
st.caption("åŸºäºâ€œæ ¸å¿ƒåº•ç¨¿â€ç†å¿µï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ·±åº¦è´¢åŠ¡æŠ¥è¡¨åˆ†æ (æ”¯æŒå¤šæœŸæ•°æ®ä¸è¶‹åŠ¿åˆ†æ)ã€‚")
st.divider()

with st.sidebar:
    st.header("âš™ï¸ æ•°æ®è¾“å…¥ä¸è®¾ç½®")
    # Display LLM Initialization Status 
    if 'run_log' in st.session_state: # Check if run_log exists
        if llm is None: # Now check the initialized llm instance
            llm_init_error_messages = [entry['message'] for entry in st.session_state.run_log if entry.get('module') == "LLM_SETUP" and entry['type'] == "ERROR"]
            llm_init_warning_messages = [entry['message'] for entry in st.session_state.run_log if entry.get('module') == "LLM_SETUP" and entry['type'] == "WARNING"]
            if llm_init_error_messages:
                st.error(f"LLM åˆå§‹åŒ–å¤±è´¥: {llm_init_error_messages[0]}")
            elif llm_init_warning_messages:
                st.warning(f"LLM é…ç½®é—®é¢˜: {llm_init_warning_messages[0]}")
            elif not any(entry.get('module') == "LLM_SETUP" for entry in st.session_state.run_log): # If no LLM_SETUP logs, means get_llm() might not have run or logged before failing
                 st.error("LLM åˆå§‹åŒ–çŠ¶æ€æœªçŸ¥æˆ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ—¥å¿—ã€‚")
        else:
            st.success("LLM å·²æˆåŠŸåˆå§‹åŒ–ã€‚")
    else: # Should not happen if run_log is initialized above
        st.warning("æ—¥å¿—ç³»ç»Ÿæœªåˆå§‹åŒ–ã€‚")


    with st.expander("1. å…¬å¸åŸºæœ¬ä¿¡æ¯ä¸åˆ†æè§’åº¦", expanded=True):
        if 'company_name_default' not in st.session_state: st.session_state.company_name_default = "ä¾‹å¦‚ï¼šè´µå·èŒ…å°è‚¡ä»½æœ‰é™å…¬å¸"
        if 'industry_default' not in st.session_state: st.session_state.industry_default = "ä¾‹å¦‚ï¼šç™½é…’åˆ¶é€ "
        if 'stock_code_default' not in st.session_state: st.session_state.stock_code_default = "ä¾‹å¦‚ï¼š600519"
        if 'is_listed_default' not in st.session_state: st.session_state.is_listed_default = 0 
        
        company_name_input = st.text_input("å…¬å¸åç§°*", value=st.session_state.company_name_default, key="company_name_input_key")
        is_listed_input = st.radio("æ˜¯å¦ä¸Šå¸‚å…¬å¸*", ("æ˜¯", "å¦"), index=st.session_state.is_listed_default, key="is_listed_radio_key")
        stock_code_input = st.text_input("è‚¡ç¥¨ä»£ç  (å¦‚é€‚ç”¨)", value=st.session_state.stock_code_default, key="stock_code_input_key")
        industry_input = st.text_input("æ‰€å±è¡Œä¸š*", value=st.session_state.industry_default, key="industry_input_key")
        analysis_perspective_options = ["è‚¡æƒæŠ•èµ„", "å€ºæƒæŠ•èµ„", "å€ºè‚¡åŒæŠ•"]
        analysis_perspective_input = st.selectbox("è´¢åŠ¡æŠ¥è¡¨åˆ†æè§’åº¦*", analysis_perspective_options, index=analysis_perspective_options.index(st.session_state.analysis_perspective_default), key="analysis_perspective_key")
        ai_planner_enabled_input = st.toggle("å¯ç”¨AIè§„åˆ’åˆ†æä»»åŠ¡?", value=st.session_state.ai_planner_toggle_default, key="ai_planner_toggle_key",help="å¼€å¯åï¼ŒAIå°†æ ¹æ®å…¬å¸ä¿¡æ¯å’Œåˆ†æè§’åº¦åŠ¨æ€é€‰æ‹©å¹¶æ’åºåˆ†ææ¨¡å—ã€‚å…³é—­åˆ™æ‰§è¡Œæ‰€æœ‰é¢„è®¾æ¨¡å—ã€‚")
    
    with st.expander("2. ï¼ˆå¯é€‰ï¼‰ä¸Šä¼ å®è§‚ç»æµåˆ†æç»“è®º", expanded=False):
        macro_analysis_file_input = st.file_uploader("ä¸Šä¼ å®è§‚ç»æµåˆ†ææ–‡ä»¶ (txt, md, pdf, docx)", type=['txt', 'md', 'pdf', 'docx'], key="macro_analysis_file_key")

    st.subheader("3. ä¸Šä¼ è´¢åŠ¡æŠ¥å‘ŠæœŸæ•°æ®") 
    if st.session_state.get('test_data_loaded_successfully', False):
        st.success("ä¸€é”®æµ‹è¯•æ•°æ®å·²åŠ è½½ã€‚æ‚¨å¯ä¿®æ”¹ä¸Šæ–¹å…¬å¸ä¿¡æ¯åå¼€å§‹åˆ†æã€‚")

    num_periods = st.number_input("é€‰æ‹©ä¸Šä¼ æŠ¥å‘ŠæœŸæ•°é‡ (æœ€å¤š4æœŸ: 3å¹´æŠ¥+1å­£æŠ¥)", min_value=1, max_value=4, value=st.session_state.num_periods_to_upload, key="num_periods_selector", disabled=st.session_state.get('test_data_loaded_successfully', False))
    if not st.session_state.get('test_data_loaded_successfully', False): st.session_state.num_periods_to_upload = num_periods

    uploaded_reports_data_sidebar = [] 
    for i in range(st.session_state.num_periods_to_upload):
        with st.container(): 
            st.markdown(f"##### ç¬¬ {i+1} æœŸæŠ¥å‘Šæ•°æ®")
            col_year, col_type = st.columns(2)
            with col_year: year_input_val = st.number_input(f"å¹´ä»½ (æœŸ {i+1})*", min_value=2000, max_value=datetime.now().year + 1, value=datetime.now().year - i, key=f"year_{i}_key")
            with col_type: period_type_input_val = st.radio(f"æŠ¥å‘Šç±»å‹ (æœŸ {i+1})*", ("å¹´æŠ¥", "å­£æŠ¥"), key=f"period_type_{i}_key", horizontal=True)
            quarter_input_val = None
            if period_type_input_val == "å­£æŠ¥": quarter_input_val = st.selectbox(f"å­£åº¦ (æœŸ {i+1})*", (1, 2, 3, 4), format_func=lambda q: f"Q{q}", key=f"quarter_{i}_key")
            period_label_input_val = f"{year_input_val} {f'Q{quarter_input_val}' if quarter_input_val else 'Annual'}"
            st.caption(f"å½“å‰è®¾å®šæ ‡ç­¾: {period_label_input_val}")
            bs_file_input_val = st.file_uploader(f"èµ„äº§è´Ÿå€ºè¡¨ (æœŸ {i+1})", type=['csv', 'xlsx'], key=f"bs_file_{i}_key")
            is_file_input_val = st.file_uploader(f"åˆ©æ¶¦è¡¨ (æœŸ {i+1})", type=['csv', 'xlsx'], key=f"is_file_{i}_key")
            cfs_file_input_val = st.file_uploader(f"ç°é‡‘æµé‡è¡¨ (æœŸ {i+1})", type=['csv', 'xlsx'], key=f"cfs_file_{i}_key")
            fn_file_input_val = st.file_uploader(f"è´¢åŠ¡æŠ¥è¡¨é™„æ³¨ (æœŸ {i+1}, å¯é€‰)", type=['txt', 'pdf', 'docx', 'md'], key=f"fn_file_{i}_key") 
            mda_file_input_val = st.file_uploader(f"ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ (æœŸ {i+1}, å¯é€‰)", type=['txt', 'pdf', 'docx', 'md'], key=f"mda_file_{i}_key") 
            uploaded_reports_data_sidebar.append({"year": year_input_val, "period_type": period_type_input_val, "quarter": quarter_input_val, "period_label": period_label_input_val, "bs_file": bs_file_input_val, "is_file": is_file_input_val, "cfs_file": cfs_file_input_val, "fn_file": fn_file_input_val, "mda_file": mda_file_input_val})
            if i < st.session_state.num_periods_to_upload -1 : st.markdown("---")

    col1_ctrl, col2_ctrl, col3_ctrl = st.columns(3) 
    with col1_ctrl: start_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True, disabled=st.session_state.analysis_started)
    with col2_ctrl: reset_button = st.button("ğŸ”„ é‡ç½®æ‰€æœ‰", use_container_width=True)
    with col3_ctrl: test_button = st.button("ğŸ§ª ä¸€é”®æµ‹è¯•", use_container_width=True, help="ä» ./test/ ç›®å½•åŠ è½½é¢„è®¾çš„ç‰§åŸè‚¡ä»½æŠ¥è¡¨æ–‡ä»¶åŠå®è§‚åˆ†ææ–‡ä»¶ã€‚")

    if test_button:
        if not get_llm_instance(): 
            st.error("LLMæœªèƒ½æˆåŠŸåˆå§‹åŒ–ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç›¸å…³é…ç½®ã€‚æ— æ³•å¼€å§‹ä¸€é”®æµ‹è¯•ã€‚")
            log_event("ERROR", "ä¸€é”®æµ‹è¯•å¤±è´¥ï¼šLLMæœªåˆå§‹åŒ–ã€‚", module_name="ä¸€é”®æµ‹è¯•")
        else:
            st.session_state.cwp = initialize_cwp()
            st.session_state.run_log = []
            st.session_state.analysis_started = False 
            st.session_state.analysis_progress = 0
            st.session_state.current_module_processing = "ä¸€é”®æµ‹è¯•æ•°æ®åŠ è½½ä¸­..."
            st.session_state.test_data_loaded_successfully = False 
            
            test_company_name = "ç‰§åŸé£Ÿå“è‚¡ä»½æœ‰é™å…¬å¸" 
            test_stock_code = "002714" 
            test_industry = "ç”ŸçŒªå…»æ®–è¡Œä¸š" 
            test_perspective = "è‚¡æƒæŠ•èµ„" 
            test_ai_planner_enabled = False 
            
            st.session_state.current_run_result_dir = create_run_result_directory(test_company_name, BASE_RESULT_DIR)
            if not st.session_state.current_run_result_dir:
                 st.error("ä¸€é”®æµ‹è¯•å¤±è´¥ï¼šæ— æ³•åˆ›å»ºç»“æœç›®å½•ã€‚")
                 log_event("ERROR", "ä¸€é”®æµ‹è¯•å¤±è´¥ï¼šæ— æ³•åˆ›å»ºç»“æœç›®å½•ã€‚", module_name="ä¸€é”®æµ‹è¯•")
            else:
                log_event("INFO", "ä¸€é”®æµ‹è¯•æ•°æ®åŠ è½½å¼€å§‹ã€‚", module_name="ä¸€é”®æµ‹è¯•")
                st.session_state.cwp['base_data']['company_info'] = {
                    "name": test_company_name, "is_listed": True,
                    "stock_code": test_stock_code, "industry": test_industry,
                    "analysis_date": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "analysis_perspective": test_perspective, 
                    "ai_planner_enabled": test_ai_planner_enabled, 
                    "macro_analysis_conclusion_text": "ä¸€é”®æµ‹è¯•ï¼šé»˜è®¤å®è§‚ç»æµåˆ†æç»“è®ºã€‚", 
                    "industry_analysis_conclusion_text": "" 
                }
                st.session_state.company_name_default = test_company_name
                st.session_state.industry_default = test_industry
                st.session_state.stock_code_default = test_stock_code
                st.session_state.is_listed_default = 0 
                st.session_state.analysis_perspective_default = test_perspective
                st.session_state.ai_planner_toggle_default = test_ai_planner_enabled
                log_event("CWP_INTERACTION", f"æµ‹è¯•å…¬å¸åŸºæœ¬ä¿¡æ¯å·²å†™å…¥æ ¸å¿ƒåº•ç¨¿: {test_company_name}, åˆ†æè§’åº¦: {test_perspective}", module_name="ä¸€é”®æµ‹è¯•")
                macro_filepath = os.path.join("test", "MACRO.md")
                if os.path.exists(macro_filepath):
                    try:
                        with open(macro_filepath, "r", encoding="utf-8") as f_macro: st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text'] = f_macro.read()
                        log_event("INFO", f"æˆåŠŸåŠ è½½æµ‹è¯•å®è§‚åˆ†ææ–‡ä»¶: {macro_filepath}", module_name="ä¸€é”®æµ‹è¯•")
                    except Exception as e: log_event("ERROR", f"åŠ è½½æµ‹è¯•å®è§‚åˆ†ææ–‡ä»¶ {macro_filepath} å¤±è´¥: {e}", module_name="ä¸€é”®æµ‹è¯•"); st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text'] = "æµ‹è¯•æ¨¡å¼ï¼šåŠ è½½ ./test/MACRO.md æ–‡ä»¶æ—¶å‡ºé”™ã€‚"
                else: log_event("WARNING", f"æµ‹è¯•å®è§‚åˆ†ææ–‡ä»¶æœªæ‰¾åˆ°: {macro_filepath}ã€‚å°†ä½¿ç”¨é»˜è®¤æç¤ºã€‚", module_name="ä¸€é”®æµ‹è¯•"); st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text'] = "æµ‹è¯•æ¨¡å¼ï¼šæœªåœ¨ ./test/ ç›®å½•æ‰¾åˆ° MACRO.md æ–‡ä»¶ã€‚"
                
                test_data_path = "test"; years_to_test = [2023, 2022, 2021]; 
                file_map = {"BS": ("balance_sheet_data", "has_bs", ".xlsx"), "IS": ("income_statement_data", "has_is", ".xlsx"), "CFS": ("cash_flow_statement_data", "has_cfs", ".xlsx"), "NTS": ("footnotes_text_original", "has_fn", ".docx"), "MDA": ("mda_text_original", "has_mda", ".md")} 
                loaded_reports_count = 0; temp_reports_list = []
                
                for year in years_to_test:
                    period_label = f"{year} Annual (æµ‹è¯•)"
                    period_entry = {"period_label": period_label, "year": year, "period_type": "å¹´æŠ¥", "quarter": None, "balance_sheet_data": None, "income_statement_data": None, "cash_flow_statement_data": None, "footnotes_text_original": "", "mda_text_original": "", "footnotes_processed_chunks": [], "mda_processed_chunks": [], "has_bs": False, "has_is": False, "has_cfs": False, "has_fn": False, "has_mda": False}
                    has_any_core_statement_for_year = False
                    for prefix, (data_key, has_key, ext) in file_map.items():
                        filename = f"{prefix}-{year}{ext}"; filepath = os.path.join(test_data_path, filename)
                        if os.path.exists(filepath):
                            try:
                                if ext == ".xlsx": 
                                    df = pd.read_excel(filepath); period_entry[data_key] = df.to_dict(); 
                                    if prefix in ["BS", "IS", "CFS"]: has_any_core_statement_for_year = True 
                                elif ext == ".docx":
                                    with open(filepath, "rb") as f_docx: doc = Document(io.BytesIO(f_docx.read())); full_text = [para.text for para in doc.paragraphs]; _=[full_text.append(f"\n--- è¡¨æ ¼ {i+1} ---\n"+"\n".join(["\t|\t".join(c.text for c in r.cells) for r in t.rows])+"\n--- è¡¨æ ¼ç»“æŸ ---\n") for i,t in enumerate(doc.tables)]; period_entry[data_key] = "\n".join(full_text)
                                    if period_entry[data_key]: period_entry[f"{'footnotes' if prefix == 'NTS' else 'mda'}_processed_chunks"] = preprocess_document_text(period_entry[data_key], 'footnotes' if prefix == 'NTS' else 'mda', period_label)
                                elif ext == ".md" or ext == ".txt": 
                                    with open(filepath, "r", encoding="utf-8") as f_text: period_entry[data_key] = f_text.read()
                                    if period_entry[data_key]: period_entry[f"{'footnotes' if prefix == 'NTS' else 'mda'}_processed_chunks"] = preprocess_document_text(period_entry[data_key], 'footnotes' if prefix == 'NTS' else 'mda', period_label)
                                period_entry[has_key] = True; log_event("INFO", f"æˆåŠŸåŠ è½½æµ‹è¯•æ–‡ä»¶: {filepath}", module_name="ä¸€é”®æµ‹è¯•")
                            except Exception as e: log_event("ERROR", f"åŠ è½½æˆ–è§£ææµ‹è¯•æ–‡ä»¶ {filepath} å¤±è´¥: {e}", module_name="ä¸€é”®æµ‹è¯•"); period_entry[has_key] = False 
                        else: log_event("WARNING", f"æµ‹è¯•æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}", module_name="ä¸€é”®æµ‹è¯•")
                    if has_any_core_statement_for_year: temp_reports_list.append(period_entry); loaded_reports_count += 1
                    else: log_event("WARNING", f"æµ‹è¯•å¹´ä»½ {year} æ— ä»»ä½•æ ¸å¿ƒExcelæŠ¥è¡¨æ–‡ä»¶ï¼Œå·²è·³è¿‡ã€‚", module_name="ä¸€é”®æµ‹è¯•")
                
                st.session_state.cwp['base_data']['financial_reports'] = temp_reports_list
                st.session_state.cwp['base_data']['financial_reports'].sort(key=lambda x: (x['year'], x['quarter'] if x['period_type'] == 'å­£æŠ¥' else 0), reverse=True)
                st.session_state.cwp['metadata_version_control']['analysis_timestamp'] = pd.Timestamp.now().isoformat()
                st.session_state.cwp['metadata_version_control']['llm_model_used'] = "DeepSeek-Reasoner (Test Mode)"
                
                if loaded_reports_count > 0:
                    st.session_state.test_data_loaded_successfully = True; st.session_state.num_periods_to_upload = loaded_reports_count 
                    st.success(f"ä¸€é”®æµ‹è¯•æ•°æ®åŠ è½½å®Œæ¯• ({loaded_reports_count} ä¸ªæŠ¥å‘ŠæœŸ)ã€‚è¯·åœ¨ä¸Šæ–¹å¡«å†™/ç¡®è®¤å…¬å¸ä¿¡æ¯ä¸åˆ†æè§’åº¦ï¼Œç„¶åç‚¹å‡»â€œå¼€å§‹åˆ†æâ€ã€‚")
                    log_event("INFO", f"ä¸€é”®æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {loaded_reports_count} ä¸ªæŠ¥å‘ŠæœŸã€‚", module_name="ä¸€é”®æµ‹è¯•")
                else: st.error("ä¸€é”®æµ‹è¯•æœªèƒ½åŠ è½½ä»»ä½•æŠ¥å‘ŠæœŸæ•°æ®ã€‚è¯·æ£€æŸ¥ `./test/` ç›®å½•ä¸‹çš„æ–‡ä»¶ã€‚"); log_event("ERROR", "ä¸€é”®æµ‹è¯•æœªèƒ½åŠ è½½ä»»ä½•æŠ¥å‘ŠæœŸæ•°æ®ã€‚", module_name="ä¸€é”®æµ‹è¯•")
                st.rerun()

    if start_button:
        current_company_name = company_name_input; current_is_listed = is_listed_input; current_stock_code = stock_code_input; current_industry = industry_input; current_analysis_perspective = analysis_perspective_input; current_macro_analysis_file = macro_analysis_file_input; current_ai_planner_enabled = ai_planner_enabled_input 
        if not current_company_name or not current_industry: error_msg = "è¯·å¡«å†™æ‰€æœ‰å¸¦ (*) çš„å¿…å¡«é¡¹ï¼šå…¬å¸åç§°å’Œæ‰€å±è¡Œä¸šã€‚"; st.error(error_msg); log_event("ERROR", f"å¼€å§‹åˆ†æå¤±è´¥ï¼š{error_msg}")
        elif not get_llm_instance(): error_msg = "LLMæœªèƒ½æˆåŠŸåˆå§‹åŒ–ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç›¸å…³é…ç½®ã€‚æ— æ³•å¼€å§‹åˆ†æã€‚"; st.error(error_msg); log_event("ERROR", f"å¼€å§‹åˆ†æå¤±è´¥ï¼š{error_msg}")
        else:
            created_run_dir = create_run_result_directory(current_company_name, BASE_RESULT_DIR)
            if not created_run_dir: log_event("ERROR", "ç”±äºæ— æ³•åˆ›å»ºç»“æœç›®å½•ï¼Œåˆ†ææµç¨‹ä¸­æ­¢ã€‚")
            else:
                st.session_state.current_run_result_dir = created_run_dir; st.session_state.analysis_started = True; st.session_state.analysis_progress = 0; st.session_state.current_module_processing = "æ•°æ®é¢„å¤„ç†ä¸è§„åˆ’ä¸­..." 
                ui_has_new_financial_report_files = any(prd.get("bs_file") or prd.get("is_file") or prd.get("cfs_file") or prd.get("fn_file") or prd.get("mda_file") for prd in uploaded_reports_data_sidebar)
                final_macro_text = st.session_state.cwp['base_data']['company_info'].get('macro_analysis_conclusion_text', "ç”¨æˆ·æœªæä¾›å®è§‚ç»æµåˆ†æç»“è®ºï¼Œä¸”æœªä»æµ‹è¯•ç›®å½•åŠ è½½é»˜è®¤æ–‡ä»¶ã€‚")
                if current_macro_analysis_file:
                    log_event("INFO", f"å¼€å§‹å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„å®è§‚ç»æµåˆ†ææ–‡ä»¶: {current_macro_analysis_file.name}", module_name="æ•°æ®é¢„å¤„ç†")
                    try:
                        if current_macro_analysis_file.name.endswith(".pdf"): pdf_reader = PyPDF2.PdfReader(current_macro_analysis_file); text = "".join(page.extract_text() for page in pdf_reader.pages if page.extract_text()); final_macro_text = text if text else f"PDF ({current_macro_analysis_file.name}) - No text extracted or empty."
                        elif current_macro_analysis_file.name.endswith(".docx"): doc = Document(current_macro_analysis_file);paras=[p.text for p in doc.paragraphs];tbls=[f"\nTable:\n"+"\n".join(["\t|\t".join(c.text for c in r.cells) for r in t.rows])+"\n--- Table End ---\n" for i,t in enumerate(doc.tables)];final_macro_text="\n".join(paras)+"\n".join(tbls) # type: ignore
                        elif current_macro_analysis_file.name.endswith((".txt",".md")): final_macro_text = current_macro_analysis_file.read().decode()
                        else: final_macro_text = f"Unsupported file type for Macro Analysis: {current_macro_analysis_file.name}"
                        if "Error reading" not in final_macro_text and "Unsupported file type" not in final_macro_text: log_event("INFO", f"ç”¨æˆ·ä¸Šä¼ çš„å®è§‚ç»æµåˆ†ææ–‡ä»¶ '{current_macro_analysis_file.name}' å¤„ç†å®Œæ¯•ã€‚", module_name="æ•°æ®é¢„å¤„ç†")
                        else: log_event("ERROR", final_macro_text, module_name="æ•°æ®é¢„å¤„ç†")
                    except Exception as e: final_macro_text = f"å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„å®è§‚åˆ†ææ–‡ä»¶ '{current_macro_analysis_file.name}' æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"; log_event("ERROR", final_macro_text, module_name="æ•°æ®é¢„å¤„ç†")
                
                if not st.session_state.test_data_loaded_successfully or ui_has_new_financial_report_files:
                    if ui_has_new_financial_report_files and st.session_state.test_data_loaded_successfully: log_event("INFO", "æ£€æµ‹åˆ°ç”¨æˆ·é€šè¿‡UIä¸Šä¼ äº†æ–°æ–‡ä»¶ï¼Œå°†ä¼˜å…ˆå¤„ç†UIæ–‡ä»¶ï¼Œè¦†ç›–å·²åŠ è½½çš„æµ‹è¯•æ•°æ®ã€‚", module_name="æ•°æ®é¢„å¤„ç†")
                    elif ui_has_new_financial_report_files: log_event("INFO", "å¤„ç†ç”¨æˆ·é€šè¿‡UIä¸Šä¼ çš„æ–‡ä»¶ã€‚", module_name="æ•°æ®é¢„å¤„ç†")
                    st.session_state.cwp = initialize_cwp(); st.session_state.run_log = [entry for entry in st.session_state.run_log if not (entry['type'] == 'CWP_INTERACTION' and ("æµ‹è¯•å…¬å¸" in entry.get('message', '') or "ç¤ºä¾‹å…¬å¸" in entry.get('message',''))) and not (entry.get('module_name') == 'ä¸€é”®æµ‹è¯•')]; st.session_state.test_data_loaded_successfully = False 
                    log_event("INFO", "åˆ†ææµç¨‹å¼€å§‹ (ç”¨æˆ·è§¦å‘ - å¤„ç†ä¸Šä¼ æ–‡ä»¶)ã€‚")
                    st.session_state.cwp['base_data']['company_info'] = {"name": current_company_name, "is_listed": current_is_listed == "æ˜¯", "stock_code": current_stock_code if current_is_listed == "æ˜¯" else "N/A", "industry": current_industry, "analysis_date": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"), "analysis_perspective": current_analysis_perspective, "ai_planner_enabled": current_ai_planner_enabled, "macro_analysis_conclusion_text": final_macro_text, "industry_analysis_conclusion_text": "è¡Œä¸šåˆ†æç»“è®ºï¼ˆåŸºäºæ³¢ç‰¹äº”åŠ›æ¨¡å‹ï¼‰å°šæœªç”Ÿæˆã€‚"}
                    processed_reports_from_ui = []
                    try:
                        for report_data in uploaded_reports_data_sidebar:
                            if not (report_data["bs_file"] and report_data["is_file"] and report_data["cfs_file"]):
                                if any([report_data["bs_file"], report_data["is_file"], report_data["cfs_file"], report_data["fn_file"], report_data["mda_file"]]): log_event("WARNING", f"æŠ¥å‘ŠæœŸ {report_data['period_label']} ç¼ºå°‘æ ¸å¿ƒä¸‰è¡¨ï¼Œå°†è·³è¿‡æ­¤æœŸã€‚", module_name="æ•°æ®é¢„å¤„ç†")
                                continue
                            period_entry = {"period_label": report_data["period_label"], "year": report_data["year"], "period_type": report_data["period_type"], "quarter": report_data["quarter"], "balance_sheet_data": None, "income_statement_data": None, "cash_flow_statement_data": None, "footnotes_text_original": "", "mda_text_original": "", "footnotes_processed_chunks": [], "mda_processed_chunks": [], "has_bs": False, "has_is": False, "has_cfs": False, "has_fn": False, "has_mda": False}
                            if report_data["bs_file"]: period_entry["balance_sheet_data"] = (pd.read_excel(report_data["bs_file"]) if report_data["bs_file"].name.endswith('xlsx') else pd.read_csv(report_data["bs_file"])).to_dict(); period_entry["has_bs"] = True
                            if report_data["is_file"]: period_entry["income_statement_data"] = (pd.read_excel(report_data["is_file"]) if report_data["is_file"].name.endswith('xlsx') else pd.read_csv(report_data["is_file"])).to_dict(); period_entry["has_is"] = True
                            if report_data["cfs_file"]: period_entry["cash_flow_statement_data"] = (pd.read_excel(report_data["cfs_file"]) if report_data["cfs_file"].name.endswith('xlsx') else pd.read_csv(report_data["cfs_file"])).to_dict(); period_entry["has_cfs"] = True
                            for file_type_key, cwp_text_key_orig, cwp_chunks_key, doc_type_name, has_key in [
                                ("fn_file", "footnotes_text_original", "footnotes_processed_chunks", "footnotes", "has_fn"), 
                                ("mda_file", "mda_text_original", "mda_processed_chunks", "mda", "has_mda")
                            ]:
                                uploaded_file = report_data[file_type_key]
                                if uploaded_file:
                                    file_content = ""
                                    if uploaded_file.name.endswith(".pdf"):
                                        try: pdf_reader = PyPDF2.PdfReader(uploaded_file); text = "".join(page.extract_text() for page in pdf_reader.pages if page.extract_text()); file_content = text if text else f"PDF ({uploaded_file.name}) - No text extracted or empty."
                                        except Exception as e: file_content = f"Error reading PDF {uploaded_file.name}: {e}"; log_event("ERROR", file_content, module_name="æ•°æ®é¢„å¤„ç†")
                                    elif uploaded_file.name.endswith(".docx"):
                                        try: doc = Document(uploaded_file); full_text = [para.text for para in doc.paragraphs];_=[full_text.append(f"\n--- è¡¨æ ¼ {i+1} ---\n"+"\n".join(["\t|\t".join(c.text for c in r.cells) for r in t.rows])+"\n--- è¡¨æ ¼ç»“æŸ ---\n") for i,t in enumerate(doc.tables)];file_content="\n".join(full_text) # type: ignore
                                        except Exception as e: file_content = f"Error reading DOCX {uploaded_file.name}: {e}"; log_event("ERROR", file_content, module_name="æ•°æ®é¢„å¤„ç†")
                                    elif uploaded_file.name.endswith((".txt", ".md")):
                                        try: file_content = uploaded_file.read().decode()
                                        except Exception as e: file_content = f"Error reading {uploaded_file.name.split('.')[-1].upper()}: {e}"; log_event("ERROR", file_content, module_name="æ•°æ®é¢„å¤„ç†")
                                    else: file_content = f"Unsupported file type: {uploaded_file.name}"; log_event("WARNING", file_content, module_name="æ•°æ®é¢„å¤„ç†")
                                    
                                    period_entry[cwp_text_key_orig] = file_content 
                                    if file_content and not file_content.startswith("Error"):
                                        st.session_state.current_module_processing = f"é¢„å¤„ç†æ–‡æ¡£: {uploaded_file.name} ({period_entry['period_label']})..."
                                        period_entry[cwp_chunks_key] = preprocess_document_text(file_content, doc_type_name, period_entry['period_label'])
                                        period_entry[has_key] = True
                                    else: period_entry[has_key] = False
                            processed_reports_from_ui.append(period_entry); log_event("CWP_INTERACTION", f"UIä¸Šä¼ çš„æŠ¥å‘ŠæœŸ {report_data['period_label']} æ•°æ®å·²å¤„ç†å¹¶é¢„åˆ†å—ã€‚", module_name="æ•°æ®é¢„å¤„ç†")
                        
                        st.session_state.cwp['base_data']['financial_reports'] = processed_reports_from_ui
                        st.session_state.cwp['base_data']['financial_reports'].sort(key=lambda x: (x['year'], x['quarter'] if x['period_type'] == 'å­£æŠ¥' else 0), reverse=True)
                        if not st.session_state.cwp['base_data']['financial_reports']: st.error("æœªèƒ½æˆåŠŸå¤„ç†ä»»ä½•é€šè¿‡UIä¸Šä¼ çš„æŠ¥å‘ŠæœŸæ•°æ®ã€‚è¯·ç¡®ä¿è‡³å°‘ä¸€ä¸ªæŠ¥å‘ŠæœŸåŒ…å«æ ¸å¿ƒä¸‰è¡¨ã€‚"); log_event("ERROR", "æœªèƒ½æˆåŠŸå¤„ç†ä»»ä½•é€šè¿‡UIä¸Šä¼ çš„æŠ¥å‘ŠæœŸæ•°æ®ã€‚", module_name="æ•°æ®é¢„å¤„ç†"); st.session_state.analysis_started = False 
                        else: log_event("INFO", f"æˆåŠŸå¤„ç† {len(st.session_state.cwp['base_data']['financial_reports'])} æœŸæ¥è‡ªUIçš„æŠ¥å‘Šæ•°æ®ã€‚", module_name="æ•°æ®é¢„å¤„ç†")
                    except Exception as e: st.error(f"å¤„ç†UIä¸Šä¼ æ–‡ä»¶å¤±è´¥: {e}"); log_event("ERROR", f"å¤„ç†UIä¸Šä¼ æ–‡ä»¶å¤±è´¥: {e}", module_name="æ•°æ®é¢„å¤„ç†"); st.session_state.analysis_started = False 
                else: 
                    log_event("INFO", "åˆ†ææµç¨‹å¼€å§‹ (ç”¨æˆ·è§¦å‘ - ä½¿ç”¨å·²åŠ è½½çš„æµ‹è¯•æ•°æ®)ã€‚")
                    st.session_state.cwp['base_data']['company_info'].update({ "name": current_company_name, "is_listed": current_is_listed == "æ˜¯", "stock_code": current_stock_code if current_is_listed == "æ˜¯" else "N/A", "industry": current_industry, "analysis_date": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"), "analysis_perspective": current_analysis_perspective, "ai_planner_enabled": current_ai_planner_enabled, "macro_analysis_conclusion_text": final_macro_text })

                log_event("CWP_INTERACTION", f"å…¬å¸åŸºæœ¬ä¿¡æ¯å·²å†™å…¥/æ›´æ–°æ ¸å¿ƒåº•ç¨¿: {st.session_state.cwp['base_data']['company_info']['name']}, åˆ†æè§’åº¦: {st.session_state.cwp['base_data']['company_info']['analysis_perspective']}, AIè§„åˆ’å™¨: {'å¯ç”¨' if st.session_state.cwp['base_data']['company_info']['ai_planner_enabled'] else 'å…³é—­'}", module_name="æ•°æ®é¢„å¤„ç†")
                if st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text'] and "ç”¨æˆ·æœªæä¾›" not in st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text'] and "å¤±è´¥" not in st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text']:
                    log_event("CWP_INTERACTION", "å®è§‚ç»æµåˆ†æç»“è®ºå·²å­˜å…¥æ ¸å¿ƒåº•ç¨¿ã€‚", module_name="æ•°æ®é¢„å¤„ç†", details={"snippet": st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text'][:100]+"..."})
                else: log_event("WARNING", f"å®è§‚ç»æµåˆ†æç»“è®ºæœ€ç»ˆä¸º: {st.session_state.cwp['base_data']['company_info']['macro_analysis_conclusion_text']}", module_name="æ•°æ®é¢„å¤„ç†")
                
                if st.session_state.analysis_started: 
                    modules_for_info_planning = []
                    if st.session_state.cwp['base_data']['company_info'].get('ai_planner_enabled', False):
                        if st.session_state.cwp['metadata_version_control'].get('ai_planned_modules') is None: 
                            st.session_state.current_module_processing = "AIä»»åŠ¡è§„åˆ’å™¨è¿è¡Œä¸­..."
                            planned_route = get_ai_planned_analysis_route(
                                st.session_state.cwp['base_data']['company_info'],
                                st.session_state.cwp['base_data']['company_info'].get('macro_analysis_conclusion_text', ''),
                                ALL_DEFINED_MODULES_LIST
                            )
                            st.session_state.cwp['metadata_version_control']['ai_planned_modules'] = planned_route
                        modules_for_info_planning = st.session_state.cwp['metadata_version_control'].get('ai_planned_modules', []) 
                        if not modules_for_info_planning: 
                            modules_for_info_planning = ALL_DEFINED_MODULES_LIST
                            log_event("WARNING", "AIè§„åˆ’æ¨¡å—åˆ—è¡¨ä¸ºç©ºï¼Œå°†ä¸ºæ‰€æœ‰é¢„å®šä¹‰æ¨¡å—è§„åˆ’ä¿¡æ¯éœ€æ±‚ã€‚", "InfoNeedsPlannerTrigger")
                    else:
                        modules_for_info_planning = ALL_DEFINED_MODULES_LIST
                    
                    if modules_for_info_planning:
                        st.session_state.current_module_processing = "æ‰¹é‡è§„åˆ’æ¨¡å—ä¿¡æ¯éœ€æ±‚ä¸­..."
                        log_event("INFO", "å¼€å§‹æ‰¹é‡è§„åˆ’æ‰€æœ‰å¾…æ‰§è¡Œæ¨¡å—çš„ä¿¡æ¯éœ€æ±‚ã€‚", "InfoNeedsPlannerTrigger")
                        
                        available_docs_summary_for_planner = "å½“å‰å·²åŠ è½½çš„ã€å¯ä¾›æå–è¯¦ç»†ä¿¡æ¯çš„æ–‡æ¡£åŒ…æ‹¬ï¼š\n"
                        for r_idx, r_entry in enumerate(st.session_state.cwp['base_data']['financial_reports']):
                            available_docs_summary_for_planner += f"- æŠ¥å‘ŠæœŸ: {r_entry['period_label']}: "
                            doc_types = []
                            if r_entry.get("footnotes_processed_chunks"): doc_types.append(f"è´¢åŠ¡æŠ¥è¡¨é™„æ³¨ (å…± {len(r_entry['footnotes_processed_chunks'])} å—)")
                            if r_entry.get("mda_processed_chunks"): doc_types.append(f"ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ (å…± {len(r_entry['mda_processed_chunks'])} å—)")
                            available_docs_summary_for_planner += ", ".join(doc_types) if doc_types else "æ— å·²å¤„ç†çš„è¡¥å……æ–‡æ¡£åˆ†å—"
                            available_docs_summary_for_planner += "\n"

                        information_needs_plan = plan_all_module_information_needs(
                            modules_to_plan_for=modules_for_info_planning,
                            company_info=st.session_state.cwp['base_data']['company_info'],
                            macro_conclusion=st.session_state.cwp['base_data']['company_info'].get('macro_analysis_conclusion_text', ''),
                            industry_conclusion=st.session_state.cwp['base_data']['company_info'].get('industry_analysis_conclusion_text', ''),
                            available_docs_summary=available_docs_summary_for_planner
                        )
                        st.session_state.cwp['metadata_version_control']['information_needs_by_module'] = information_needs_plan
                        log_event("CWP_INTERACTION", "æ‰€æœ‰æ¨¡å—çš„ä¿¡æ¯éœ€æ±‚è§„åˆ’ç»“æœå·²å­˜å…¥æ ¸å¿ƒåº•ç¨¿ã€‚", "InfoNeedsPlannerTrigger", {"num_modules_planned": len(information_needs_plan)})
                    else:
                         log_event("WARNING", "æ²¡æœ‰æ¨¡å—éœ€è¦è¿›è¡Œä¿¡æ¯éœ€æ±‚è§„åˆ’ (æ¨¡å—åˆ—è¡¨ä¸ºç©º)ã€‚", "InfoNeedsPlannerTrigger")

                    st.session_state.cwp['metadata_version_control']['analysis_timestamp'] = pd.Timestamp.now().isoformat()
                    st.session_state.cwp['metadata_version_control']['llm_model_used'] = "DeepSeek-Reasoner"
                    st.rerun()

    if reset_button:
        # ... (Unchanged)
        st.session_state.cwp = initialize_cwp()
        st.session_state.analysis_started = False; st.session_state.analysis_progress = 0
        st.session_state.current_module_processing = ""; st.session_state.num_periods_to_upload = 1
        st.session_state.run_log = []; st.session_state.test_data_loaded_successfully = False
        st.session_state.company_name_default = "ä¾‹å¦‚ï¼šè´µå·èŒ…å°è‚¡ä»½æœ‰é™å…¬å¸"; st.session_state.industry_default = "ä¾‹å¦‚ï¼šç™½é…’åˆ¶é€ "
        st.session_state.stock_code_default = "ä¾‹å¦‚ï¼š600519"; st.session_state.is_listed_default = 0
        st.session_state.analysis_perspective_default = "è‚¡æƒæŠ•èµ„"; st.session_state.ai_planner_toggle_default = False
        st.session_state.current_run_result_dir = None 
        st.success("æ‰€æœ‰è¾“å…¥å’Œåˆ†æç»“æœå·²é‡ç½®ã€‚"); st.rerun()

    if st.session_state.analysis_started:
        st.sidebar.progress(st.session_state.analysis_progress / 100, text=st.session_state.current_module_processing)

# --- Main UI Logic ---
if not st.session_state.analysis_started:
    st.info("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥å…¬å¸ä¿¡æ¯å¹¶ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨ï¼ˆæ”¯æŒå¤šæœŸï¼‰ï¼Œç„¶åç‚¹å‡»â€œå¼€å§‹åˆ†æâ€ã€‚æˆ–ç‚¹å‡»â€œä¸€é”®æµ‹è¯•â€ä»æœ¬åœ° `./test/` ç›®å½•åŠ è½½é¢„è®¾æ–‡ä»¶ã€‚")
else:
    modules_to_execute_ordered = []
    sections_to_execute_for_display = {} 
    TOTAL_MODULES_TO_RUN_CURRENT = 0 
    
    if st.session_state.cwp['base_data']['company_info'].get('ai_planner_enabled', False):
        planned_modules = st.session_state.cwp['metadata_version_control'].get('ai_planned_modules') 
        if planned_modules: 
            modules_to_execute_ordered = planned_modules
            temp_sections = {}
            for sec, mods_in_framework in ANALYSIS_FRAMEWORK_SECTIONS.items():
                current_sec_mods = [m for m in mods_in_framework if m in planned_modules]
                if current_sec_mods:
                    temp_sections[sec] = sorted(current_sec_mods, key=lambda x: planned_modules.index(x) if x in planned_modules else float('inf'))
            sections_to_execute_for_display = temp_sections
            TOTAL_MODULES_TO_RUN_CURRENT = len(modules_to_execute_ordered)
            st.session_state.cwp['metadata_version_control']['ai_planned_sections_for_display'] = sections_to_execute_for_display 
        else: 
            log_event("WARNING", "AIè§„åˆ’å™¨å¯ç”¨ä½†æœªè¿”å›æœ‰æ•ˆæ¨¡å—è®¡åˆ’ï¼Œå°†æ‰§è¡Œæ‰€æœ‰é¢„å®šä¹‰æ¨¡å—ã€‚", "MainLogic")
            modules_to_execute_ordered = ALL_DEFINED_MODULES_LIST 
            sections_to_execute_for_display = ANALYSIS_FRAMEWORK_SECTIONS
            TOTAL_MODULES_TO_RUN_CURRENT = TOTAL_MODULES_COUNT 
            st.session_state.cwp['metadata_version_control']['ai_planned_sections_for_display'] = ANALYSIS_FRAMEWORK_SECTIONS
    else: 
        modules_to_execute_ordered = ALL_DEFINED_MODULES_LIST 
        sections_to_execute_for_display = ANALYSIS_FRAMEWORK_SECTIONS
        TOTAL_MODULES_TO_RUN_CURRENT = TOTAL_MODULES_COUNT 
        st.session_state.cwp['metadata_version_control']['ai_planned_sections_for_display'] = ANALYSIS_FRAMEWORK_SECTIONS 
    
    if not st.session_state.cwp['metadata_version_control'].get('information_needs_by_module') and modules_to_execute_ordered:
        st.session_state.current_module_processing = "é¦–æ¬¡è¿è¡Œæ—¶æ‰¹é‡è§„åˆ’æ¨¡å—ä¿¡æ¯éœ€æ±‚ä¸­..."
        log_event("INFO", "é¦–æ¬¡è¿è¡Œæˆ–AIè§„åˆ’æ¨¡å—æ›´æ–°ï¼Œå¼€å§‹æ‰¹é‡è§„åˆ’ä¿¡æ¯éœ€æ±‚ã€‚", "MainLogic")
        available_docs_summary_for_planner = "å¯æŸ¥è¯¢æ–‡æ¡£åŒ…æ‹¬ï¼š\n"
        for r_idx, r_entry in enumerate(st.session_state.cwp['base_data']['financial_reports']):
            available_docs_summary_for_planner += f"- æŠ¥å‘ŠæœŸ: {r_entry['period_label']}: "
            doc_types = []
            if r_entry.get("footnotes_processed_chunks"): doc_types.append(f"è´¢åŠ¡æŠ¥è¡¨é™„æ³¨ (å…± {len(r_entry['footnotes_processed_chunks'])} å—)")
            if r_entry.get("mda_processed_chunks"): doc_types.append(f"ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ (å…± {len(r_entry['mda_processed_chunks'])} å—)")
            available_docs_summary_for_planner += ", ".join(doc_types) if doc_types else "æ— å·²å¤„ç†çš„è¡¥å……æ–‡æ¡£åˆ†å—"
            available_docs_summary_for_planner += "\n"
        information_needs_plan = plan_all_module_information_needs(
            modules_to_plan_for=modules_to_execute_ordered,
            company_info=st.session_state.cwp['base_data']['company_info'],
            macro_conclusion=st.session_state.cwp['base_data']['company_info'].get('macro_analysis_conclusion_text', ''),
            industry_conclusion=st.session_state.cwp['base_data']['company_info'].get('industry_analysis_conclusion_text', ''),
            available_docs_summary=available_docs_summary_for_planner
        )
        st.session_state.cwp['metadata_version_control']['information_needs_by_module'] = information_needs_plan
        log_event("CWP_INTERACTION", "æ‰€æœ‰æ¨¡å—çš„ä¿¡æ¯éœ€æ±‚è§„åˆ’ç»“æœå·²å­˜å…¥æ ¸å¿ƒåº•ç¨¿ã€‚", "MainLogic", {"num_modules_planned": len(information_needs_plan)})
        st.rerun() 

    analysis_in_progress_main = len(st.session_state.cwp['analytical_module_outputs']) < TOTAL_MODULES_TO_RUN_CURRENT

    if analysis_in_progress_main and st.session_state.cwp['metadata_version_control'].get('information_needs_by_module'): 
        st.header("ğŸš€ åˆ†æè¿›è¡Œä¸­...")
        col_prog_bar, col_prog_text = st.columns([3, 1])
        with col_prog_bar: st.progress(st.session_state.analysis_progress / 100 if st.session_state.analysis_progress is not None and TOTAL_MODULES_TO_RUN_CURRENT > 0 else 0)
        with col_prog_text: st.write(f"{st.session_state.analysis_progress if st.session_state.analysis_progress is not None else 0}% å®Œæˆ")
        st.info(f"å½“å‰æ­£åœ¨å¤„ç†æ¨¡å—: **{st.session_state.current_module_processing}**")
        completed_module_names = list(st.session_state.cwp['analytical_module_outputs'].keys())
        pending_module_names = [m for m in modules_to_execute_ordered if m not in completed_module_names]
        st.markdown("---"); col_completed, col_pending = st.columns(2)
        with col_completed:
            st.subheader(f"å·²å®Œæˆæ¨¡å— ({len(completed_module_names)}/{TOTAL_MODULES_TO_RUN_CURRENT}):")
            if completed_module_names: 
                for mod_item_val_c in completed_module_names: 
                    if isinstance(mod_item_val_c, str) and mod_item_val_c:
                        st.markdown(f"- âœ… {mod_item_val_c}") 
                    else: 
                        log_event("ERROR", f"Skipping display: Invalid item in completed_module_names. Type: {type(mod_item_val_c)}, Value: '{mod_item_val_c}'", "UI_Error_Display")
            else: st.caption("æš‚æ— å·²å®Œæˆæ¨¡å—ã€‚")
        with col_pending:
            st.subheader("å¾…å¤„ç†æ¨¡å—:")
            if pending_module_names: 
                for mod_item_val_p in pending_module_names: 
                    if isinstance(mod_item_val_p, str) and mod_item_val_p:
                        st.markdown(f"- â³ {mod_item_val_p}") 
                    else:
                        log_event("ERROR", f"Skipping display: Invalid item in pending_module_names. Type: {type(mod_item_val_p)}, Value: '{mod_item_val_p}'", "UI_Error_Display")
            else: st.caption("æ‰€æœ‰è§„åˆ’æ¨¡å—å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—æˆ–å·²å®Œæˆã€‚")
        st.markdown("---")

        next_module_to_run = None; next_section_key_for_module = None
        for mod_name in modules_to_execute_ordered:
            if mod_name not in st.session_state.cwp['analytical_module_outputs']:
                next_module_to_run = mod_name
                for sec, mods_in_sec in ANALYSIS_FRAMEWORK_SECTIONS.items(): 
                    if mod_name in mods_in_sec: next_section_key_for_module = sec; break
                break
        if next_module_to_run and next_section_key_for_module:
            run_llm_module_analysis(next_module_to_run, next_section_key_for_module)
            st.rerun() 
        elif not pending_module_names and len(completed_module_names) >= TOTAL_MODULES_TO_RUN_CURRENT: 
             st.session_state.current_module_processing = "âœ… åˆ†æå…¨éƒ¨å®Œæˆï¼"
             log_event("INFO", "æ‰€æœ‰è§„åˆ’çš„åˆ†ææ¨¡å—å·²å®Œæˆï¼ˆä¸»å¾ªç¯æ£€æµ‹ï¼‰ã€‚")
             if not st.session_state.cwp['integrated_insights'].get('key_risks') and TOTAL_MODULES_TO_RUN_CURRENT > 0 : consolidate_risks_and_opportunities() 
             if not st.session_state.cwp['integrated_insights'].get('overall_summary') and TOTAL_MODULES_TO_RUN_CURRENT > 0: generate_and_save_html_report()
             st.rerun()
    elif not analysis_in_progress_main: # Analysis is complete
        tab_titles = ["âš™ï¸ è¿è¡Œæ—¥å¿—", "ğŸ“Š æ€»è§ˆä¸æ‘˜è¦", "ğŸŒ æˆ˜ç•¥ä¸ç¯å¢ƒ", "ğŸ“ˆ ä¸šç»©ä¸æ•ˆç‡", "ğŸ’° ç›ˆåˆ©ä¸ä¼šè®¡", "ğŸ“‰ é£é™©ä¸å¿å€º", "ğŸš€ å¢é•¿ä¸æŒç»­", "ğŸ”® é¢„æµ‹ä¸å»ºæ¨¡", "âš–ï¸ å…¬å¸ä¼°å€¼", "ğŸ“ æ ¸å¿ƒåº•ç¨¿è¿½è¸ª"]
        tabs = st.tabs(tab_titles)
        with tabs[0]: 
            st.header("âš™ï¸ è¿è¡Œæ—¥å¿—"); st.markdown("æŒ‰æ—¶é—´å€’åºæ˜¾ç¤ºç³»ç»Ÿè¿è¡Œè¿‡ç¨‹ä¸­çš„å…³é”®äº‹ä»¶ã€‚")
            if st.button("åˆ·æ–°æ—¥å¿—", key="refresh_log_button_main_final"): st.rerun()
            if not st.session_state.run_log: st.info("æš‚æ— è¿è¡Œæ—¥å¿—ã€‚è¯·å¼€å§‹åˆ†æä»¥ç”Ÿæˆæ—¥å¿—ã€‚")
            else:
                log_container = st.container(height=600); 
                for entry in st.session_state.run_log: 
                    log_class = f"log-entry log-entry-{entry['type']}"; module_prefix = f"æ¨¡å—: `{entry['module']}` - " if 'module' in entry else "ç³»ç»Ÿ - "; message_display = entry['message']
                    if entry.get('details'):
                        details_str_parts = []; 
                        if 'query' in entry['details']: details_str_parts.append(f"æŸ¥è¯¢: `{entry['details']['query']}`")
                        if 'result_snippet' in entry['details']: details_str_parts.append(f"ç»“æœæ‘˜è¦: `{entry['details']['result_snippet']}`")
                        if 'summary_snippet' in entry['details']: details_str_parts.append(f"æ‘˜è¦: `{entry['details']['summary_snippet']}`")
                        if 'inventory' in entry['details']: details_str_parts.append(f"æ–‡æ¡£æ¸…å•: {entry['details']['inventory']}")
                        if 'prompt_length' in entry['details']: details_str_parts.append(f"æç¤ºé•¿åº¦: {entry['details']['prompt_length']}")
                        if 'tool_name' in entry['details']: details_str_parts.append(f"å·¥å…·: `{entry['details']['tool_name']}`")
                        if 'args' in entry['details']: args_display = entry['details']['args'];_ = json.dumps(args_display, ensure_ascii=False) if isinstance(args_display, dict) else str(args_display); details_str_parts.append(f"å‚æ•°: `{_}`")
                        if 'conversation' in entry['details']: 
                             try: 
                                 conv_str = json.dumps(entry['details']['conversation'], ensure_ascii=False, indent=2)
                                 details_str_parts.append(f"å¯¹è¯å†å²: \n```json\n{conv_str}\n```")
                             except TypeError: details_str_parts.append("å¯¹è¯å†å²: (åºåˆ—åŒ–å¤±è´¥)")
                        elif 'full_prompt' in entry['details']: 
                             details_str_parts.append(f"å®Œæ•´æç¤º: \n```\n{entry['details']['full_prompt']}\n```")

                        if details_str_parts: message_display += " (" + ", ".join(details_str_parts) + ")"
                    with log_container: st.markdown(f"<div class='{log_class}'><b>{entry['timestamp']} [{entry['type']}]</b> {module_prefix}{message_display}</div>", unsafe_allow_html=True)
        with tabs[1]:
            st.header("ğŸ“Š åˆ†ææ€»è§ˆä¸æ ¸å¿ƒç»“è®ºæ‘˜è¦")
            if st.session_state.analysis_progress >= 100 and llm: 
                if st.session_state.cwp['integrated_insights'].get('key_risks'):
                    st.subheader("ä¸»è¦é£é™©ç‚¹")
                    for risk_idx, risk in enumerate(st.session_state.cwp['integrated_insights']['key_risks']):
                        with st.expander(f"é£é™©: {risk.get('description', 'N/A')[:50]}... (ID: {risk.get('id', 'N/A')})", expanded=False): 
                            st.markdown(f"**æè¿°:** {risk.get('description', 'N/A')}"); st.markdown(f"**åˆ†ç±»:** {risk.get('category', 'N/A')}"); st.markdown(f"**æ½œåœ¨å½±å“:** {risk.get('potential_impact', 'N/A')}")
                            if risk.get('source_modules'): st.markdown(f"**æ¥æºæ¨¡å—:** {', '.join(risk['source_modules'])}")
                            if risk.get('mitigating_factors_observed'): st.markdown(f"**ç¼“è§£å› ç´ :** {risk['mitigating_factors_observed']}")
                            if risk.get('notes_for_further_investigation'): st.markdown(f"**è¿›ä¸€æ­¥è°ƒæŸ¥:** {risk['notes_for_further_investigation']}")
                if st.session_state.cwp['integrated_insights'].get('key_opportunities'):
                    st.subheader("ä¸»è¦æœºé‡ç‚¹")
                    for opp_idx, opp in enumerate(st.session_state.cwp['integrated_insights']['key_opportunities']):
                         with st.expander(f"æœºé‡: {opp.get('description', 'N/A')[:50]}... (ID: {opp.get('id', 'N/A')})", expanded=False): 
                            st.markdown(f"**æè¿°:** {opp.get('description', 'N/A')}"); st.markdown(f"**åˆ†ç±»:** {opp.get('category', 'N/A')}"); st.markdown(f"**æ½œåœ¨æ”¶ç›Š:** {opp.get('potential_benefit', 'N/A')}")
                            if opp.get('source_modules'): st.markdown(f"**æ¥æºæ¨¡å—:** {', '.join(opp['source_modules'])}")
                            if opp.get('actionability_notes'): st.markdown(f"**è¡ŒåŠ¨å»ºè®®/å…³æ³¨ç‚¹:** {opp['actionability_notes']}")
                st.divider(); st.subheader("æœ€ç»ˆæ€»ä½“è´¢åŠ¡åˆ†ææ‘˜è¦")
                cwp_module_summaries = []; ordered_module_names_final = [mod_name for section_modules in ANALYSIS_FRAMEWORK_SECTIONS.values() for mod_name in section_modules] 
                for mod_name_sum in ordered_module_names_final:
                    if mod_name_sum in st.session_state.cwp['analytical_module_outputs']:
                        mod_output_sum = st.session_state.cwp['analytical_module_outputs'][mod_name_sum]
                        if mod_output_sum.get('status') == 'Completed':
                            summary_to_use = mod_output_sum.get('abbreviated_summary') or mod_output_sum.get('text_summary', ''); confidence_to_use = mod_output_sum.get('confidence_score', 'N/A')
                            cwp_module_summaries.append(f"æ¨¡å— '{mod_name_sum}' (ç½®ä¿¡åº¦: {confidence_to_use}): {summary_to_use[:200]}...")
                report_labels_summary = ', '.join([r['period_label'] for r in st.session_state.cwp['base_data']['financial_reports']])
                _, local_latest_period_label_summary = get_latest_period_info(st.session_state.cwp) 
                final_current_overall_conclusion = st.session_state.cwp['integrated_insights'].get('current_overall_financial_conclusion', "æœªèƒ½ç”Ÿæˆè¿­ä»£çš„æ€»ä½“ç»“è®ºã€‚")
                contradiction_log_content = "æ— è®°å½•çš„çŸ›ç›¾ç‚¹ã€‚"; 
                if st.session_state.cwp['integrated_insights'].get('contradiction_logbook'):
                    contradiction_log_content = "\nåˆ†æè¿‡ç¨‹ä¸­è®°å½•çš„æ½œåœ¨çŸ›ç›¾ç‚¹ï¼š\n"; 
                    for item_idx, item in enumerate(st.session_state.cwp['integrated_insights']['contradiction_logbook']): contradiction_log_content += f"{item_idx+1}. æ¨¡å—'{item['module_name']}' (ç½®ä¿¡åº¦: {item['module_confidence']}) æŒ‡å‡º: {item['contradiction_description']}\n"
                macro_conclusion_for_summary = st.session_state.cwp['base_data']['company_info'].get('macro_analysis_conclusion_text', 'ç”¨æˆ·æœªæä¾›å®è§‚ç»æµåˆ†æç»“è®ºã€‚')
                industry_conclusion_for_summary = st.session_state.cwp['base_data']['company_info'].get('industry_analysis_conclusion_text', 'è¡Œä¸šåˆ†æç»“è®ºå°šæœªç”Ÿæˆã€‚')
                summary_prompt_template = f"""
                æ‚¨æ˜¯ä¸€ä½èµ„æ·±çš„è´¢åŠ¡åˆ†æå¸ˆ...æ’°å†™ä¸€ä»½å…¨é¢ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„æœ€ç»ˆæ€»ä½“è´¢åŠ¡åˆ†ææ‘˜è¦ã€‚
                **å…¬å¸åç§°:** {st.session_state.cwp['base_data']['company_info']['name']} **æ‰€å±è¡Œä¸š:** {st.session_state.cwp['base_data']['company_info']['industry']} **åˆ†æè§’åº¦:** {st.session_state.cwp['base_data']['company_info'].get('analysis_perspective', 'æœªæŒ‡å®š')}
                **å·²åˆ†æçš„æŠ¥å‘ŠæœŸåŒ…æ‹¬:** {report_labels_summary}. **æœ€æ–°æŠ¥å‘ŠæœŸä¸º:** {local_latest_period_label_summary}.
                **A. ç”¨æˆ·æä¾›çš„å®è§‚ç»æµåˆ†æç»“è®ºï¼š**\n```{macro_conclusion_for_summary}```
                **B. ç³»ç»Ÿç”Ÿæˆçš„è¡Œä¸šåˆ†æç»“è®ºï¼š**\n```{industry_conclusion_for_summary}```
                **C. æœ€ç»ˆçš„â€œï¼ˆå½“å‰ï¼‰å…¬å¸æ€»ä½“è´¢åŠ¡åˆ†æç»“è®ºâ€ï¼š**\n```{final_current_overall_conclusion}```
                **D. åˆ†æè¿‡ç¨‹ä¸­è®°å½•çš„â€œçŸ›ç›¾ç‚¹è®°å½•æœ¬â€ï¼š**\n```{contradiction_log_content}```
                **E. å·²è¯†åˆ«çš„å…³é”®é£é™©ç‚¹ï¼š**\n```{json.dumps(st.session_state.cwp['integrated_insights'].get('key_risks', []), ensure_ascii=False, indent=2)}```
                **F. å·²è¯†åˆ«çš„å…³é”®æœºé‡ç‚¹ï¼š**\n```{json.dumps(st.session_state.cwp['integrated_insights'].get('key_opportunities', []), ensure_ascii=False, indent=2)}```
                **G. å„ä¸ªç‹¬ç«‹åˆ†ææ¨¡å—çš„æ‘˜è¦ï¼š**\n```{ "\n".join(cwp_module_summaries)}```
                **æ’°å†™è¦æ±‚ï¼š** 1. å…¨é¢æ€§ä¸æ·±åº¦ï¼ˆ2000-3000æ±‰å­—ï¼‰ã€‚2. æ•´åˆæ€§ï¼ˆä½“ç°åˆ†æè§’åº¦ï¼Œç»“åˆå®è§‚è¡Œä¸šï¼‰ã€‚3. å…³æ³¨çŸ›ç›¾ç‚¹ã€é£é™©ä¸æœºé‡ã€‚4. ç»“æ„å»ºè®®ï¼ˆå®è§‚è¡Œä¸šèƒŒæ™¯ã€å…¬å¸æ¦‚å†µã€è´¢åŠ¡æ ¸å¿ƒã€ä¼˜åŠ¿æœºé‡ã€é£é™©æŒ‘æˆ˜ã€å¢é•¿æŒç»­ã€ä¼°å€¼ã€æ€»ç»“å±•æœ›ï¼‰ã€‚
                è¯·ç”Ÿæˆæœ€ç»ˆæ€»ä½“è´¢åŠ¡åˆ†ææ‘˜è¦ã€‚
                """
                try:
                    summary_messages = [{"role": "user", "content": summary_prompt_template}]; summary_response = llm.invoke(summary_messages) 
                    final_summary = summary_response.content if hasattr(summary_response, 'content') else str(summary_response)
                    st.session_state.cwp['integrated_insights']['overall_summary'] = final_summary; st.markdown(final_summary)
                    log_event("CWP_INTERACTION", "æœ€ç»ˆæ€»ä½“è´¢åŠ¡åˆ†ææ‘˜è¦å·²ç”Ÿæˆå¹¶å­˜å…¥æ ¸å¿ƒåº•ç¨¿ã€‚", module_name="æ€»è§ˆä¸æ‘˜è¦")
                except Exception as e: st.error(f"ç”Ÿæˆæœ€ç»ˆæ‘˜è¦å¤±è´¥: {e}"); log_event("ERROR", f"ç”Ÿæˆæœ€ç»ˆæ‘˜è¦å¤±è´¥: {e}", module_name="æ€»è§ˆä¸æ‘˜è¦")
            elif not llm and st.session_state.analysis_started: st.warning("LLM æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆæœ€ç»ˆæ‘˜è¦ã€‚")
            elif st.session_state.analysis_started: st.info("æ‰€æœ‰åˆ†ææ¨¡å—å®Œæˆåï¼Œå°†åœ¨æ­¤å¤„ç”Ÿæˆæ€»ä½“æ‘˜è¦ã€‚")
            else: st.info("è¯·å…ˆå¼€å§‹åˆ†æã€‚")

        # Display other analysis module tabs
        ordered_sections_for_display = sections_to_execute_for_display 
        tab_offset = 2 
        current_tab_idx = 0
        for section_title_key, modules_in_section in ordered_sections_for_display.items():
            if not modules_in_section: continue 
            original_section_index = -1
            for idx, (orig_sec_key, _) in enumerate(ANALYSIS_FRAMEWORK_SECTIONS.items()):
                if orig_sec_key == section_title_key: original_section_index = idx; break
            if original_section_index != -1:
                display_tab_index = original_section_index + tab_offset
                if display_tab_index < len(tabs) -1: 
                    with tabs[display_tab_index]:
                        st.header(f"ç¬¬ {original_section_index + 1} éƒ¨åˆ†ï¼š{section_title_key}") 
                        st.markdown(f"*æœ¬éƒ¨åˆ†åŒ…å« {len(modules_in_section)} ä¸ªåˆ†ææ¨¡å—ã€‚*")
                        for module_idx, module_name in enumerate(modules_in_section): 
                            with st.expander(f"**{module_name}**", expanded=False): 
                                output_data = st.session_state.cwp['analytical_module_outputs'].get(module_name)
                                if output_data:
                                    st.markdown(f"**ç½®ä¿¡åº¦:** {output_data.get('confidence_score', 'N/A')}") 
                                    st.markdown(output_data.get("text_summary", "æ— æ–‡æœ¬æ‘˜è¦ã€‚")) 
                                    if output_data.get("structured_data"): st.caption("ç»“æ„åŒ–æ•°æ®:"); st.json(output_data["structured_data"], expanded=False)
                                    st.caption(f"çŠ¶æ€: {output_data.get('status', 'N/A')} | æ—¶é—´: {output_data.get('timestamp', 'N/A')}")
                                    col_prompt, col_messages = st.columns(2)
                                    with col_prompt:
                                        if st.toggle("æ˜¾ç¤ºä½¿ç”¨çš„æç¤º", key=f"toggle_prompt_{module_name}_{original_section_index}_{display_tab_index}_{module_idx}", value=False): 
                                            st.text_area("Prompt Used", value=output_data.get("prompt_used", "æ— æç¤ºä¿¡æ¯è®°å½•ã€‚"), height=200, disabled=True, key=f"prompt_disp_{module_name}_{original_section_index}_{display_tab_index}_{module_idx}")
                                    with col_messages:
                                         if output_data.get("message_history") and st.toggle("æ˜¾ç¤ºäº¤äº’å†å²", key=f"toggle_messages_{module_name}_{original_section_index}_{display_tab_index}_{module_idx}", value=False): 
                                            st.json(output_data.get("message_history"), expanded=False)
                                else: st.info(f"æ¨¡å— '{module_name}' åˆ†æç»“æœå¾…ç”Ÿæˆæˆ–æœªè¢«AIè§„åˆ’å™¨é€‰ä¸­ã€‚")
            current_tab_idx +=1
        
        with tabs[-1]: 
            st.header("ğŸ“ æ ¸å¿ƒåº•ç¨¿å®æ—¶è¿½è¸ª")
            with st.expander("1. åŸºç¡€æ•°æ®å±‚", expanded=False):
                st.subheader("å…¬å¸åŸºæœ¬ä¿¡æ¯"); st.json(st.session_state.cwp['base_data']['company_info'], expanded=True)
                st.subheader("å·²ä¸Šä¼ è´¢åŠ¡æŠ¥å‘ŠæœŸæ•°æ®")
                if st.session_state.cwp['base_data']['financial_reports']:
                    for i, report_entry in enumerate(st.session_state.cwp['base_data']['financial_reports']):
                        with st.container(border=True):
                            st.markdown(f"**æŠ¥å‘ŠæœŸ {i+1}: {report_entry['period_label']} ({report_entry['period_type']})**")
                            st.caption(f"å¹´ä»½: {report_entry['year']}" + (f", å­£åº¦: Q{report_entry['quarter']}" if report_entry['quarter'] else ""))
                            docs_present = []; 
                            if report_entry.get("has_bs"): docs_present.append("èµ„äº§è´Ÿå€ºè¡¨")
                            if report_entry.get("has_is"): docs_present.append("åˆ©æ¶¦è¡¨")
                            if report_entry.get("has_cfs"): docs_present.append("ç°é‡‘æµé‡è¡¨")
                            if report_entry.get("footnotes_processed_chunks"): docs_present.append(f"é™„æ³¨ ({len(report_entry['footnotes_processed_chunks'])} å—)") 
                            if report_entry.get("mda_processed_chunks"): docs_present.append(f"MD&A ({len(report_entry['mda_processed_chunks'])} å—)") 
                            st.write(f"å·²ä¸Šä¼ /å¤„ç†æ–‡ä»¶: {', '.join(docs_present) if docs_present else 'æ— æ ¸å¿ƒæ–‡ä»¶æˆ–æœªå¤„ç†'}")
                            
                            if report_entry.get("footnotes_processed_chunks"):
                                with st.popover(f"æŸ¥çœ‹ {report_entry['period_label']} é™„æ³¨åˆ†å—æ¦‚è¿°", use_container_width=True):
                                    for chunk_idx, chunk_data in enumerate(report_entry["footnotes_processed_chunks"]):
                                        st.markdown(f"**å— {chunk_idx+1} (ID: {chunk_data['chunk_id']}) æ¦‚è¿°:**")
                                        st.caption(chunk_data['overview_text'])
                                        st.divider()
                            if report_entry.get("mda_processed_chunks"):
                                with st.popover(f"æŸ¥çœ‹ {report_entry['period_label']} MD&Aåˆ†å—æ¦‚è¿°", use_container_width=True):
                                    for chunk_idx, chunk_data in enumerate(report_entry["mda_processed_chunks"]):
                                        st.markdown(f"**å— {chunk_idx+1} (ID: {chunk_data['chunk_id']}) æ¦‚è¿°:**")
                                        st.caption(chunk_data['overview_text'])
                                        st.divider()
                else: st.caption("å°šæœªä¸Šä¼ æˆ–å¤„ç†ä»»ä½•æŠ¥å‘ŠæœŸæ•°æ®ã€‚")
            
            with st.expander("è¿­ä»£æ€»ç»“ä¸çŸ›ç›¾ç‚¹", expanded=True):
                st.subheader("å½“å‰å…¬å¸æ€»ä½“è´¢åŠ¡åˆ†æç»“è®º (è¿­ä»£æ›´æ–°)")
                st.markdown(st.session_state.cwp['integrated_insights'].get('current_overall_financial_conclusion', 'æš‚æ— '))
                st.subheader("çŸ›ç›¾ç‚¹è®°å½•æœ¬")
                if st.session_state.cwp['integrated_insights'].get('contradiction_logbook'):
                    for idx, entry in enumerate(st.session_state.cwp['integrated_insights']['contradiction_logbook']):
                        st.markdown(f"**çŸ›ç›¾ç‚¹ {idx+1}:**")
                        st.markdown(f"- **è®°å½•æ—¶é—´:** {entry['timestamp']}")
                        st.markdown(f"- **å¼•å‘æ¨¡å—:** {entry['module_name']} (ç½®ä¿¡åº¦: {entry['module_confidence']})")
                        st.markdown(f"- **çŸ›ç›¾æè¿°:** {entry['contradiction_description']}")
                        with st.popover(f"æŸ¥çœ‹çŸ›ç›¾ç‚¹ {idx+1} ç›¸å…³ç»“è®ºç‰‡æ®µ", key=f"popover_contradiction_{idx}_cwp_key"):
                            st.markdown(f"**æ¨¡å—ç»“è®ºç‰‡æ®µ:**\n```\n{entry['module_finding_snippet']}\n```")
                            st.markdown(f"**å‰æœŸæ€»ä½“ç»“è®ºç‰‡æ®µ:**\n```\n{entry['previous_overall_conclusion_snippet']}\n```")
                        st.divider()
                else:
                    st.markdown("æš‚æ— è®°å½•çš„çŸ›ç›¾ç‚¹ã€‚")
            
            with st.expander("å…³é”®é£é™©ä¸æœºé‡", expanded=True):
                st.subheader("è¯†åˆ«å‡ºçš„å…³é”®é£é™©ç‚¹")
                if st.session_state.cwp['integrated_insights'].get('key_risks'):
                    for risk_idx_cwp, risk in enumerate(st.session_state.cwp['integrated_insights']['key_risks']):
                        st.markdown(f"- **{risk.get('description')}** (åˆ†ç±»: {risk.get('category','N/A')}, å½±å“: {risk.get('potential_impact','N/A')})", key=f"cwp_risk_{risk_idx_cwp}")
                else:
                    st.markdown("æš‚æœªæ±‡æ€»å…³é”®é£é™©ã€‚")
                
                st.subheader("è¯†åˆ«å‡ºçš„å…³é”®æœºé‡ç‚¹")
                if st.session_state.cwp['integrated_insights'].get('key_opportunities'):
                    for opp_idx_cwp, opp in enumerate(st.session_state.cwp['integrated_insights']['key_opportunities']):
                        st.markdown(f"- **{opp.get('description')}** (åˆ†ç±»: {opp.get('category','N/A')}, æ”¶ç›Š: {opp.get('potential_benefit','N/A')})", key=f"cwp_opp_{opp_idx_cwp}")
                else:
                    st.markdown("æš‚æœªæ±‡æ€»å…³é”®æœºé‡ã€‚")


            with st.expander("åˆ†ææ¨¡å—è¾“å‡ºå±‚", expanded=False):
                if st.session_state.cwp['analytical_module_outputs']:
                    for module_name, output_val in st.session_state.cwp['analytical_module_outputs'].items():
                        with st.container(border=True):
                            st.markdown(f"##### {module_name}")
                            st.markdown(f"**çŠ¶æ€:** {output_val.get('status', 'N/A')} | **æ—¶é—´:** {output_val.get('timestamp', 'N/A')} | **ç½®ä¿¡åº¦:** {output_val.get('confidence_score', 'N/A')}")
                            if output_val.get("text_summary"): st.caption("æ–‡æœ¬æ‘˜è¦:"); st.markdown(f"> {output_val['text_summary'][:300]}...")
                            if output_val.get("abbreviated_summary"): st.caption("ç¼©ç•¥æ‘˜è¦:"); st.markdown(f"> {output_val['abbreviated_summary'][:300]}...") 
                            if output_val.get("structured_data"): st.caption("ç»“æ„åŒ–æ•°æ®:"); st.json(output_val["structured_data"], expanded=False)
                            col_prompt_cwp, col_messages_cwp = st.columns(2)
                            with col_prompt_cwp:
                                if output_val.get("prompt_used") and st.toggle("æ˜¾ç¤ºä½¿ç”¨çš„æç¤º", key=f"toggle_prompt_cwp_{module_name}_cwp_disp_key_v5", value=False): 
                                     st.text_area("Prompt Used (CWP)", value=output_val["prompt_used"], height=150, disabled=True, key=f"prompt_cwp_disp_{module_name}_cwp_area_key_v5")
                            with col_messages_cwp:
                                if output_val.get("message_history") and st.toggle("æ˜¾ç¤ºäº¤äº’å†å²", key=f"toggle_messages_cwp_{module_name}_cwp_disp_key_v5", value=False): 
                                    st.json(output_val.get("message_history"), expanded=False)
                else: st.info("åˆ†ææ¨¡å—çš„è¾“å‡ºå°†åœ¨æ­¤å¤„é€æ¡è®°å½•ã€‚")
            with st.expander("æœ€ç»ˆç»¼åˆæ´å¯Ÿä¸ç»“è®ºå±‚ (æ‘˜è¦)", expanded=False): 
                st.markdown(f"**æœ€ç»ˆæ€»ä½“åˆ†ææ‘˜è¦:**"); st.markdown(f"{st.session_state.cwp['integrated_insights'].get('overall_summary', 'åˆ†æå®Œæˆåç”Ÿæˆã€‚')}")
            with st.expander("å…ƒæ•°æ®ä¸ç‰ˆæœ¬æ§åˆ¶å±‚", expanded=False): 
                st.json(st.session_state.cwp['metadata_version_control'])

